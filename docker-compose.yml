version: "3.9"

services:
  trainer:
    build: ./0_train
    container_name: qwen-trainer
    tty: true
    stdin_open: true
    shm_size: "16gb"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_HOME=/root/.cache/huggingface
      - HF_HUB_DISABLE_SYMLINKS_WARNING=1
      - MODEL_NAME=Qwen3-4B-Thinking-2507
      - CUDA_VISIBLE_DEVICES=0
      - NUM_TRAIN_EPOCH=8

    volumes:
      - ./data:/workspace/data
      - ./models:/workspace/models
      - ./outputs:/workspace/outputs

    working_dir: /workspace

    command: ["python", "main.py"]