version: "3.9"

services:
  trainer:
    build: ./0_train
    container_name: qwen-trainer
    tty: true
    stdin_open: true
    shm_size: "16gb"

    # Доступ к GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Переменные окружения для Hugging Face и CUDA
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_HOME=/root/.cache/huggingface
      - HF_HUB_DISABLE_SYMLINKS_WARNING=1
      - MODEL_NAME=models/Qwen2.5-1.5B-instruct
      - CUDA_VISIBLE_DEVICES=0   # если несколько карт — можно указать id

    volumes:
      - ./data:/workspace/data                              # датасет
      - ./models:/workspace/models           # кэш HF моделей
      - ./outputs:/workspace/outputs                       # сохранение чекпоинтов

    working_dir: /workspace

    command: ["python", "main.py"]